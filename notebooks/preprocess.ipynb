{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python378jvsc74a57bd02fdd69b04bc0b4232b4cb4be2320e67faa4480b0241575de8b26e2d9f5e03d76",
   "display_name": "Python 3.7.8 64-bit ('anaconda3-5.3.1': pyenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from utils import read_pickle_from_file, write_pickle_to_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_form(form):\n",
    "    string = ''\n",
    "    for i in re.findall(r\"[A-Z][^A-Z]*\", form):\n",
    "        elem = re.match(r\"\\D+\", i).group()\n",
    "        num = i.replace(elem, \"\")\n",
    "        if num == \"\":\n",
    "            string += f\"{elem} \"\n",
    "        else:\n",
    "            string += f\"{elem} {str(num)} \"\n",
    "    return string.rstrip(' ')\n",
    "\n",
    "\n",
    "PATTEN = re.compile('(\\d+|[A-Z][a-z]?|[^A-Za-z\\d/]|/[a-z])')\n",
    "def l_split(s):\n",
    "    return ' '.join(re.findall(PATTEN,s))\n",
    "\n",
    "def split_form3(form):\n",
    "    form = form.split(' ')\n",
    "    # print(form)\n",
    "    string = []\n",
    "    for i, x in enumerate(form):\n",
    "        if x.isdigit():\n",
    "            string.extend(list(x))\n",
    "        else:\n",
    "            string.append(x)\n",
    "\n",
    "    return  ' '.join(string)\n",
    "\n",
    "def split_form2(form):\n",
    "    string = ''\n",
    "    for i in re.findall(r\"[a-z][^a-z]*\", form):\n",
    "        elem = i[0]\n",
    "        num = i.replace(elem, \"\").replace('/', \"\")\n",
    "        num_string = ''\n",
    "        for j in re.findall(r\"[0-9]+[^0-9]*\", num):\n",
    "            num_list = list(re.findall(r'\\d+', j))\n",
    "            assert len(num_list) == 1, f\"len(num_list) != 1\"\n",
    "            _num = num_list[0]\n",
    "            if j == _num:\n",
    "                num_string += f\"{_num} \"\n",
    "            else:\n",
    "                extra = j.replace(_num, \"\")\n",
    "                num_string += f\"{_num} {' '.join(list(extra))} \"\n",
    "        string += f\"/{elem} {num_string}\"\n",
    "    return string.rstrip(' ')\n",
    "\n",
    "# ====================================================\n",
    "# Tokenizer\n",
    "# ====================================================\n",
    "data_dir = \"../data/\"\n",
    "class YNakamaTokenizer(object):\n",
    "\n",
    "    def __init__(self, is_load=None):\n",
    "        self.stoi = {}\n",
    "        self.itos = {}\n",
    "\n",
    "        if is_load is not None:\n",
    "            self.stoi = read_pickle_from_file(os.path.join(data_dir, is_load))\n",
    "            self.itos = {k: v for v, k in self.stoi.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.stoi)\n",
    "\n",
    "    def build_vocab(self, text):\n",
    "        vocab = set()\n",
    "        for t in text:\n",
    "            vocab.update(t.split(' '))\n",
    "        vocab = sorted(vocab)\n",
    "        vocab.append('<sos>')\n",
    "        vocab.append('<eos>')\n",
    "        vocab.append('<pad>')\n",
    "        for i, s in enumerate(vocab):\n",
    "            self.stoi[s] = i\n",
    "        self.itos = {k: v for v, k in self.stoi.items()}\n",
    "\n",
    "    def one_text_to_sequence(self, text):\n",
    "        sequence = []\n",
    "        sequence.append(self.stoi['<sos>'])\n",
    "        for s in text.split(' '):\n",
    "            sequence.append(self.stoi[s])\n",
    "        sequence.append(self.stoi['<eos>'])\n",
    "        return sequence\n",
    "\n",
    "    def one_sequence_to_text(self, sequence):\n",
    "        return ''.join(list(map(lambda i: self.itos[i], sequence)))\n",
    "\n",
    "    def one_predict_to_inchi(self, predict):\n",
    "        inchi = 'InChI=1S/'\n",
    "        for p in predict:\n",
    "            if p == self.stoi['<eos>'] or p == self.stoi['<pad>']:\n",
    "                break\n",
    "            inchi += self.itos[p]\n",
    "        return inchi\n",
    "\n",
    "    # ---\n",
    "    def text_to_sequence(self, text):\n",
    "        sequence = [\n",
    "            self.one_text_to_sequence(t)\n",
    "            for t in text\n",
    "        ]\n",
    "        return sequence\n",
    "\n",
    "    def sequence_to_text(self, sequence):\n",
    "        text = [\n",
    "            self.one_sequence_to_text(s)\n",
    "            for s in sequence\n",
    "        ]\n",
    "        return text\n",
    "\n",
    "    def predict_to_inchi(self, predict):\n",
    "        inchi = [\n",
    "            self.one_predict_to_inchi(p)\n",
    "            for p in predict\n",
    "        ]\n",
    "        return inchi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"../data/train_labels.csv\")\n",
    "df = pd.read_csv(\"../data/agree_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1533328.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2af9f76b908c4298b4ea422207ff3e7b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1533328.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "76eb563049fe40d99f3a03d8b1b490a8"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df['InChI_1'] = df['InChI'].progress_apply(lambda x: x.split('/')[1])\n",
    "df['InChI_text'] = df['InChI'].apply(lambda x: x[9:]).progress_apply(l_split).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       image_id                                              InChI  \\\n",
       "0  00000d2a601c  InChI=1S/C10H14BrN5S/c1-6-10(11)9(16(3)14-6)4-...   \n",
       "1  00001f7fc849  InChI=1S/C14H18ClN3/c1-2-7-16-9-13-10-17-14(18...   \n",
       "2  000037687605  InChI=1S/C16H13BrN2O/c1-11(20)12-6-7-13(9-18)1...   \n",
       "3  00004b6d55b6  InChI=1S/C14H19FN4O/c1-14(2,3)12-13(16)17-18-1...   \n",
       "4  000085dab281  InChI=1S/C20H38O/c1-20(2)18-16-14-12-10-8-6-4-...   \n",
       "\n",
       "       InChI_1                                         InChI_text  \n",
       "0  C10H14BrN5S  C 10 H 14 Br N 5 S /c 1 - 6 - 10 ( 11 ) 9 ( 16...  \n",
       "1   C14H18ClN3  C 14 H 18 Cl N 3 /c 1 - 2 - 7 - 16 - 9 - 13 - ...  \n",
       "2  C16H13BrN2O  C 16 H 13 Br N 2 O /c 1 - 11 ( 20 ) 12 - 6 - 7...  \n",
       "3   C14H19FN4O  C 14 H 19 F N 4 O /c 1 - 14 ( 2 , 3 ) 12 - 13 ...  \n",
       "4      C20H38O  C 20 H 38 O /c 1 - 20 ( 2 ) 18 - 16 - 14 - 12 ...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>InChI</th>\n      <th>InChI_1</th>\n      <th>InChI_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00000d2a601c</td>\n      <td>InChI=1S/C10H14BrN5S/c1-6-10(11)9(16(3)14-6)4-...</td>\n      <td>C10H14BrN5S</td>\n      <td>C 10 H 14 Br N 5 S /c 1 - 6 - 10 ( 11 ) 9 ( 16...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00001f7fc849</td>\n      <td>InChI=1S/C14H18ClN3/c1-2-7-16-9-13-10-17-14(18...</td>\n      <td>C14H18ClN3</td>\n      <td>C 14 H 18 Cl N 3 /c 1 - 2 - 7 - 16 - 9 - 13 - ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000037687605</td>\n      <td>InChI=1S/C16H13BrN2O/c1-11(20)12-6-7-13(9-18)1...</td>\n      <td>C16H13BrN2O</td>\n      <td>C 16 H 13 Br N 2 O /c 1 - 11 ( 20 ) 12 - 6 - 7...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00004b6d55b6</td>\n      <td>InChI=1S/C14H19FN4O/c1-14(2,3)12-13(16)17-18-1...</td>\n      <td>C14H19FN4O</td>\n      <td>C 14 H 19 F N 4 O /c 1 - 14 ( 2 , 3 ) 12 - 13 ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>000085dab281</td>\n      <td>InChI=1S/C20H38O/c1-20(2)18-16-14-12-10-8-6-4-...</td>\n      <td>C20H38O</td>\n      <td>C 20 H 38 O /c 1 - 20 ( 2 ) 18 - 16 - 14 - 12 ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df.copy()\n",
    "# train_df = train_df[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df[\"text\"] = train_df.InChI_text.apply(split_form3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1533328, 5)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1533328, 4)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'(': 0, ')': 1, '+': 2, ',': 3, '-': 4, '/b': 5, '/c': 6, '/h': 7, '/i': 8, '/m': 9, '/s': 10, '/t': 11, '0': 12, '1': 13, '2': 14, '3': 15, '4': 16, '5': 17, '6': 18, '7': 19, '8': 20, '9': 21, 'B': 22, 'Br': 23, 'C': 24, 'Cl': 25, 'D': 26, 'F': 27, 'H': 28, 'I': 29, 'N': 30, 'O': 31, 'P': 32, 'S': 33, 'Si': 34, 'T': 35, '<sos>': 36, '<eos>': 37, '<pad>': 38}\n"
     ]
    }
   ],
   "source": [
    "tokenizer = YNakamaTokenizer(is_load = \"small_tokenizer.stoi.pickle\")\n",
    "# print('Saved tokenizer')\n",
    "print(tokenizer.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1533328.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fdd235f5a1d748b68817691ca9a495a4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lengths = []\n",
    "seqs = []\n",
    "tk0 = tqdm(train_df['text'].values, total=len(train_df))\n",
    "for text in tk0:\n",
    "    try:\n",
    "        seq = tokenizer.one_text_to_sequence(text)\n",
    "        length = len(seq) - 2\n",
    "    except:\n",
    "        seq=  \"None\"\n",
    "        length = -1\n",
    "    lengths.append(length)\n",
    "    seqs.append(seq)\n",
    "train_df['length'] = lengths\n",
    "train_df['sequence'] = seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1533328"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "train_df[train_df[\"sequence\"] != \"None\"].shape[0] + train_df[train_df[\"sequence\"] == \"None\"].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(397, 7)"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "train_df[train_df[\"length\"] == -1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_pickle_to_file(\"../data/df_test_small.csv.pickle\", train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}